import streamlit as st
import pandas as pd
import joblib
import numpy as np

# Cargar los modelos y el encoder guardados
try:
    modelo_rf = joblib.load('churn_model_rf.pkl')
    modelo_xgb = joblib.load('churn_model_xgb.pkl')
    oneHE = joblib.load('oneHE_encoder.pkl')
    st.success("Modelos y encoder cargados correctamente.")
except FileNotFoundError:
    st.error("Error: AsegÃºrate de que los archivos 'churn_model_rf.pkl', 'churn_model_xgb.pkl' y 'oneHE_encoder.pkl' estÃ©n en el mismo directorio.")
    st.stop()  # Detener la ejecuciÃ³n si los archivos no se encuentran

# Estilo de la interfaz de usuario
st.title("ğŸ“Š PredicciÃ³n de CancelaciÃ³n de Clientes (Churn) - Grupo 4")
st.markdown(
    """
    ## IntroducciÃ³n
    Esta herramienta predice si un cliente abandonarÃ¡ el servicio (churn) basÃ¡ndose en varios factores. 
    Selecciona un modelo y llena los datos del cliente para hacer la predicciÃ³n.
    """
)

# SelecciÃ³n de modelo
model_choice = st.radio("ğŸ” **Selecciona el modelo para la predicciÃ³n**", ["Random Forest", "XGBoost"], index=0)

# Subir archivo .pkl (modelo) si se selecciona "Custom model"
uploaded_model = None
if model_choice == "Random Forest":
    uploaded_model = st.file_uploader("ğŸ“‚ Subir el modelo Random Forest (.pkl)", type=["pkl"])
elif model_choice == "XGBoost":
    uploaded_model = st.file_uploader("ğŸ“‚ Subir el modelo XGBoost (.pkl)", type=["pkl"])

# Subir archivo OneHotEncoder
uploaded_oneHE_encoder = st.file_uploader("ğŸ“‚ Subir el OneHotEncoder (.pkl)", type=["pkl"])

if uploaded_model is not None and uploaded_oneHE_encoder is not None:
    try:
        # Cargar el modelo y encoder desde los archivos subidos
        model = joblib.load(uploaded_model)
        oneHE = joblib.load(uploaded_oneHE_encoder)

        # Formulario para ingresar datos de un nuevo cliente manualmente
        st.subheader("ğŸ”¢ **Ingresa los Datos del Cliente para PredicciÃ³n**")

        # Campos para ingresar datos del cliente
        gender = st.selectbox("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ GÃ©nero", ["Male", "Female"])
        seniorcitizen = st.selectbox("ğŸ‘µ Senior Citizen", ["No", "Yes"])
        partner = st.selectbox("â¤ï¸ Tiene pareja", ["No", "Yes"])
        dependents = st.selectbox("ğŸ‘¶ Tiene dependientes", ["No", "Yes"])
        phoneservice = st.selectbox("ğŸ“ Servicio telefÃ³nico", ["No", "Yes"])
        paperlessbilling = st.selectbox("ğŸ’³ Factura sin papel", ["No", "Yes"])

        tenure = st.number_input("ğŸ“… AntigÃ¼edad (meses)", min_value=0, max_value=100)
        monthlycharges = st.number_input("ğŸ’¸ Cargo mensual", min_value=0)
        totalcharges = st.number_input("ğŸ’° Cargo total", min_value=0)

        # Crear el DataFrame con los datos ingresados
        input_data = pd.DataFrame({
            'gender': [gender],
            'seniorcitizen': [1 if seniorcitizen == "Yes" else 0],
            'partner': [1 if partner == "Yes" else 0],
            'dependents': [1 if dependents == "Yes" else 0],
            'phoneservice': [1 if phoneservice == "Yes" else 0],
            'paperlessbilling': [1 if paperlessbilling == "Yes" else 0],
            'tenure': [tenure],
            'monthlycharges': [monthlycharges],
            'totalcharges': [totalcharges]
        })

        # Preprocesamiento de los datos ingresados
        input_data_encoded = pd.get_dummies(input_data, drop_first=True)

        # Obtener las columnas del modelo dependiendo del tipo de modelo
        if model_choice == "Random Forest":
            model_columns = model.feature_names_in_  # Obtenemos las columnas que fueron usadas en el modelo
        elif model_choice == "XGBoost":
            model_columns = model.get_booster().feature_names  # Obtener los nombres de las caracterÃ­sticas de XGBoost

        # Asegurar que las columnas del DataFrame de entrada coincidan con las del modelo
        input_data_encoded = input_data_encoded.reindex(columns=model_columns, fill_value=0)

        # Realizar la predicciÃ³n
        if st.button("ğŸ”® Predecir Churn"):
            try:
                pred_input = model.predict(input_data_encoded)
                prob_input = model.predict_proba(input_data_encoded)[:, 1]

                st.write(f"**PredicciÃ³n Churn:** {'Yes' if pred_input[0] == 1 else 'No'}")
                st.write(f"**Probabilidad de Churn:** {prob_input[0]:.2f}")
            except Exception as e:
                st.error(f"OcurriÃ³ un error con la predicciÃ³n: {e}")

    except Exception as e:
        st.error(f"OcurriÃ³ un error: {e}")
else:
    st.info("Por favor, sube el archivo del modelo y el OneHotEncoder para continuar.")
